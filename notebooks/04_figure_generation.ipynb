{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd1OkctdTpEd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"results/iou_summary.json\") as f:\n",
        "    iou_summary = json.load(f)\n",
        "\n",
        "with open(\"results/deletion_summary.json\") as f:\n",
        "    deletion_summary = json.load(f)\n",
        "\n",
        "with open(\"results/insertion_summary.json\") as f:\n",
        "    insertion_summary = json.load(f)\n"
      ],
      "metadata": {
        "id": "02AiG3Q5T4hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summary_to_df(summary, metric_name):\n",
        "    rows = []\n",
        "    for method, stats in summary.items():\n",
        "        rows.append({\n",
        "            \"method\": method,\n",
        "            \"mean\": stats[\"mean\"],\n",
        "            \"std\": stats[\"std\"],\n",
        "            \"metric\": metric_name\n",
        "        })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "iou_df = summary_to_df(iou_summary, \"IoU\")\n",
        "del_df = summary_to_df(deletion_summary, \"Deletion AUC\")\n",
        "ins_df = summary_to_df(insertion_summary, \"Insertion AUC\")\n"
      ],
      "metadata": {
        "id": "4VcaUugxT6o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(iou_df[\"method\"], iou_df[\"mean\"], yerr=iou_df[\"std\"], capsize=4)\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.title(\"Localization Accuracy (IoU)\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-7RUcOYrT9MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(del_df[\"method\"], del_df[\"mean\"], yerr=del_df[\"std\"], capsize=4)\n",
        "plt.ylabel(\"Deletion AUC\")\n",
        "plt.title(\"Deletion Metric\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aZTMx_OEUBRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(ins_df[\"method\"], ins_df[\"mean\"], yerr=ins_df[\"std\"], capsize=4)\n",
        "plt.ylabel(\"Insertion AUC\")\n",
        "plt.title(\"Insertion Metric\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yIwUS5T7UCHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "survey_df = pd.read_csv(\"data/survey_results_summary.csv\")\n",
        "survey_df.head()\n"
      ],
      "metadata": {
        "id": "pA4IK4FXUF55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "likert_df = survey_df[survey_df[\"category\"] == \"likert\"]\n",
        "\n",
        "metrics = likert_df[\"metric\"].unique()\n",
        "\n",
        "for metric in metrics:\n",
        "    subset = likert_df[likert_df[\"metric\"] == metric]\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(subset[\"method\"], subset[\"mean\"], yerr=subset[\"std\"], capsize=4)\n",
        "    plt.ylabel(\"Mean rating\")\n",
        "    plt.title(metric.capitalize())\n",
        "    plt.xticks(rotation=20)\n",
        "    plt.ylim(1,5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "MwZrqyXBUGsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_df = survey_df[\n",
        "    (survey_df[\"category\"] == \"overall\") &\n",
        "    (survey_df[\"metric\"] == \"mean_rating\")\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(overall_df[\"method\"], overall_df[\"mean\"], yerr=overall_df[\"std\"], capsize=4)\n",
        "plt.ylabel(\"Overall rating\")\n",
        "plt.title(\"Overall Explanation Quality\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.ylim(1,5)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jjnoDqysUKFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pref_df = survey_df[survey_df[\"category\"] == \"preference\"]\n",
        "\n",
        "for metric in pref_df[\"metric\"].unique():\n",
        "    subset = pref_df[pref_df[\"metric\"] == metric]\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.bar(subset[\"method\"], subset[\"percentage\"])\n",
        "    plt.ylabel(\"Percentage (%)\")\n",
        "    plt.title(metric.replace(\"_\", \" \").capitalize())\n",
        "    plt.xticks(rotation=20)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "KmK3gR_GUMEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_df = survey_df[\n",
        "    (survey_df[\"category\"] == \"cognitive_load\") &\n",
        "    (survey_df[\"metric\"] == \"average_rank\")\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(rank_df[\"method\"], rank_df[\"mean_rank\"])\n",
        "plt.ylabel(\"Average rank (lower is better)\")\n",
        "plt.title(\"Cognitive Load\")\n",
        "plt.xticks(rotation=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1dF43JMjUMsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"results/figures\", exist_ok=True)\n",
        "\n",
        "# Example save (repeat as needed)\n",
        "# plt.savefig(\"results/figures/iou_comparison.png\", dpi=300, bbox_inches=\"tight\")\n"
      ],
      "metadata": {
        "id": "tE38XTlJUQYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}