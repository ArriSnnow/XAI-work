{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mM0UKeUIdRv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.models import get_device, load_model, get_preprocess, get_target_layer\n",
        "from src.data import load_voc2007_val\n",
        "from src.explainers import (\n",
        "    GradCAM,\n",
        "    saliency_map,\n",
        "    integrated_gradients,\n",
        "    lime_explanation\n",
        ")\n",
        "from src.visualization import render_attribution, bgr_to_rgb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_device()\n",
        "model = load_model(device)\n",
        "preprocess = get_preprocess()\n",
        "target_layer = get_target_layer(model, layer_type=\"late\")\n"
      ],
      "metadata": {
        "id": "66rcX5voIunA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_voc2007_val(root=\"./data\", download=True)\n",
        "print(f\"Loaded VOC 2007 val set with {len(dataset)} images\")"
      ],
      "metadata": {
        "id": "lnNxzUIcIxAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a fixed image index (same as used in experiments)\n",
        "idx = 0  # change only if you used a different fixed index\n",
        "\n",
        "img_pil, gt_boxes = dataset[idx]"
      ],
      "metadata": {
        "id": "vSVUz6aRI3Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PIL → RGB numpy\n",
        "img_rgb = np.array(img_pil)\n",
        "\n",
        "# RGB → BGR for OpenCV-based visualization\n",
        "img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "# Preprocess for model\n",
        "input_tensor = preprocess(img_pil).unsqueeze(0).to(device)\n"
      ],
      "metadata": {
        "id": "S18kgO_fI5ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "    target_class = outputs.argmax(dim=1).item()\n",
        "\n",
        "print(\"Target class index:\", target_class)\n"
      ],
      "metadata": {
        "id": "M18PYYVvI84h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sal_map = saliency_map(model, input_tensor, target_class)"
      ],
      "metadata": {
        "id": "RlRBl-AgJBiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ig_map = integrated_gradients(\n",
        "    model,\n",
        "    input_tensor,\n",
        "    target_class,\n",
        "    baseline=None,\n",
        "    steps=50\n",
        ")"
      ],
      "metadata": {
        "id": "Pj7633GEJD5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lime_map = lime_explanation(\n",
        "    model,\n",
        "    preprocess,\n",
        "    img_rgb,\n",
        "    target_class,\n",
        "    num_samples=1000\n",
        ")"
      ],
      "metadata": {
        "id": "-cV2Yu09JGsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "methods = {\n",
        "    \"Grad-CAM\": cam_map,\n",
        "    \"Saliency\": sal_map,\n",
        "    \"Integrated Gradients\": ig_map,\n",
        "    \"LIME\": lime_map\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, (name, attr) in enumerate(methods.items()):\n",
        "    overlay = render_attribution(img_bgr, attr, alpha=0.5)\n",
        "    overlay_rgb = bgr_to_rgb(overlay)\n",
        "\n",
        "    plt.subplot(2, 2, i + 1)\n",
        "    plt.imshow(overlay_rgb)\n",
        "    plt.title(name)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3z9nc0gyJKVu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}