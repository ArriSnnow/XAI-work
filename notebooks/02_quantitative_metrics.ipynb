{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n19ybM8GOM-7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from src.models import get_device, load_model, get_preprocess, get_target_layer\n",
        "from src.data import load_voc2007_val\n",
        "from src.explainers import (\n",
        "    GradCAM,\n",
        "    saliency_map,\n",
        "    integrated_gradients,\n",
        "    lime_explanation\n",
        ")\n",
        "from src.metrics import (\n",
        "    binarize_attribution,\n",
        "    compute_iou,\n",
        "    deletion_curve,\n",
        "    insertion_curve,\n",
        "    compute_auc\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = get_device()\n",
        "model = load_model(device)\n",
        "preprocess = get_preprocess()\n",
        "target_layer = get_target_layer(model, layer_type=\"late\")\n"
      ],
      "metadata": {
        "id": "o6llYUaRSG5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_voc2007_val(root=\"./data\", download=True)\n",
        "print(f\"Loaded VOC 2007 val set with {len(dataset)} images\")\n"
      ],
      "metadata": {
        "id": "cDQ_GaslSI7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixed indices used for evaluation\n",
        "image_indices = list(range(20))  # change only if your paper used a different count\n"
      ],
      "metadata": {
        "id": "GT_aETonSMa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iou_results = {\n",
        "    \"Grad-CAM\": [],\n",
        "    \"Saliency\": [],\n",
        "    \"Integrated Gradients\": [],\n",
        "    \"LIME\": []\n",
        "}\n",
        "\n",
        "deletion_auc = {k: [] for k in iou_results}\n",
        "insertion_auc = {k: [] for k in iou_results}\n"
      ],
      "metadata": {
        "id": "qnz_JrlVSPGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in image_indices:\n",
        "    img_pil, gt_boxes = dataset[idx]\n",
        "\n",
        "    # Prepare input\n",
        "    input_tensor = preprocess(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        target_class = outputs.argmax(dim=1).item()\n",
        "\n",
        "    # --- Generate explanations ---\n",
        "    gradcam = GradCAM(model, target_layer)\n",
        "    cam_map = gradcam(input_tensor, target_class)\n",
        "\n",
        "    sal_map = saliency_map(model, input_tensor, target_class)\n",
        "\n",
        "    ig_map = integrated_gradients(\n",
        "        model,\n",
        "        input_tensor,\n",
        "        target_class,\n",
        "        baseline=None,\n",
        "        steps=50\n",
        "    )\n",
        "\n",
        "    img_rgb = np.array(img_pil)\n",
        "    lime_map = lime_explanation(\n",
        "        model,\n",
        "        preprocess,\n",
        "        img_rgb,\n",
        "        target_class,\n",
        "        num_samples=1000\n",
        "    )\n",
        "\n",
        "    explanations = {\n",
        "        \"Grad-CAM\": cam_map,\n",
        "        \"Saliency\": sal_map,\n",
        "        \"Integrated Gradients\": ig_map,\n",
        "        \"LIME\": lime_map\n",
        "    }\n",
        "\n",
        "    # --- IoU ---\n",
        "    for name, attr in explanations.items():\n",
        "        binary = binarize_attribution(attr, threshold=0.5)\n",
        "        iou = compute_iou(binary, gt_boxes)\n",
        "        iou_results[name].append(iou)\n",
        "\n",
        "    # --- Deletion / Insertion ---\n",
        "    for name, attr in explanations.items():\n",
        "        del_curve = deletion_curve(\n",
        "            model, input_tensor, attr, target_class, steps=50\n",
        "        )\n",
        "        ins_curve = insertion_curve(\n",
        "            model, input_tensor, attr, target_class, steps=50\n",
        "        )\n",
        "\n",
        "        deletion_auc[name].append(compute_auc(del_curve))\n",
        "        insertion_auc[name].append(compute_auc(ins_curve))\n"
      ],
      "metadata": {
        "id": "lQj7YFbQSRLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(results):\n",
        "    return {\n",
        "        \"mean\": float(np.mean(results)),\n",
        "        \"std\": float(np.std(results))\n",
        "    }\n",
        "\n",
        "iou_summary = {k: summarize(v) for k, v in iou_results.items()}\n",
        "deletion_summary = {k: summarize(v) for k, v in deletion_auc.items()}\n",
        "insertion_summary = {k: summarize(v) for k, v in insertion_auc.items()}\n"
      ],
      "metadata": {
        "id": "-aTI2Q9uSTZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== IoU ===\")\n",
        "for k, v in iou_summary.items():\n",
        "    print(k, v)\n",
        "\n",
        "print(\"\\n=== Deletion AUC ===\")\n",
        "for k, v in deletion_summary.items():\n",
        "    print(k, v)\n",
        "\n",
        "print(\"\\n=== Insertion AUC ===\")\n",
        "for k, v in insertion_summary.items():\n",
        "    print(k, v)\n"
      ],
      "metadata": {
        "id": "tk4eoOhSSWxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "Path(\"results\").mkdir(exist_ok=True)\n",
        "\n",
        "with open(\"results/iou_summary.json\", \"w\") as f:\n",
        "    json.dump(iou_summary, f, indent=2)\n",
        "\n",
        "with open(\"results/deletion_summary.json\", \"w\") as f:\n",
        "    json.dump(deletion_summary, f, indent=2)\n",
        "\n",
        "with open(\"results/insertion_summary.json\", \"w\") as f:\n",
        "    json.dump(insertion_summary, f, indent=2)\n"
      ],
      "metadata": {
        "id": "CH7BIYzOSaii"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}